geom_segment(aes(x = par, y = 0, xend = par, yend = 0.5),
data = FittedPsychometricFunctions_WithoutOutliers$par %>% filter(parn == "p1" ),
size = 1) +
facet_grid(id~velH) +
geom_point(data = Data_GLM2 %>% filter(id %in% c("Across All", "s01","s02", "s03", "s04", "s05", "s06", "s08")), aes(Difference,Yes/Total,color = Congruent)), alpha = 0.2, size = 0.7) +
scale_color_manual(name = "",
values = c(Red,BlauUB,LightBlauUB),
labels = c("No Motion","Same Direction","Opposite Directions")) +
scale_x_continuous("Difference between Comparison and Test (m/s)") +
scale_y_continuous("Probability to choose Test",breaks = c(0.2,0.5,0.8)) +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey") +
theme(legend.position = "top") +
ggtitle("Full psychometric functions")
Data_GLM2 %>% filter(id %in% c("Across All", "s01","s02", "s03", "s04", "s05", "s06", "s08"))
ggplot(FittedPsychometricFunctions_WithoutOutliers$curves, aes(x,y,color=Congruent)) +
geom_line(size = 1) +
geom_segment(aes(x = par, y = 0, xend = par, yend = 0.5),
data = FittedPsychometricFunctions_WithoutOutliers$par %>% filter(parn == "p1" ),
size = 1) +
facet_grid(id~velH) +
geom_point(data = Data_GLM2 %>% filter(id %in% c("Across All", "s01","s02", "s03", "s04", "s05", "s06", "s08")), aes(Difference,Yes/Total,color = Congruent), alpha = 0.2, size = 0.7) +
scale_color_manual(name = "",
values = c(Red,BlauUB,LightBlauUB),
labels = c("No Motion","Same Direction","Opposite Directions")) +
scale_x_continuous("Difference between Comparison and Test (m/s)") +
scale_y_continuous("Probability to choose Test",breaks = c(0.2,0.5,0.8)) +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey") +
theme(legend.position = "top") +
ggtitle("Full psychometric functions")
ggplot(FittedPsychometricFunctions_WithoutOutliers$curves, aes(x,y,color=Congruent)) +
geom_line(size = 1) +
geom_segment(aes(x = par, y = 0, xend = par, yend = 0.5),
data = FittedPsychometricFunctions_WithoutOutliers$par %>% filter(parn == "p1" ),
size = 1) +
facet_grid(id~velH) +
geom_point(data = rbind(Data_GLM2,Data_GLM) %>% filter(id %in% c("Across All", "s01","s02", "s03", "s04", "s05", "s06", "s08")), aes(Difference,Yes/Total,color = Congruent), alpha = 0.2, size = 0.7) +
scale_color_manual(name = "",
values = c(Red,BlauUB,LightBlauUB),
labels = c("No Motion","Same Direction","Opposite Directions")) +
scale_x_continuous("Difference between Comparison and Test (m/s)") +
scale_y_continuous("Probability to choose Test",breaks = c(0.2,0.5,0.8)) +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey") +
theme(legend.position = "top") +
ggtitle("Full psychometric functions")
ggplot(FittedPsychometricFunctions_WithoutOutliers$curves, aes(x,y,color=Congruent)) +
geom_line(size = 1) +
geom_segment(aes(x = par, y = 0, xend = par, yend = 0.5),
data = FittedPsychometricFunctions_WithoutOutliers$par %>% filter(parn == "p1" ),
size = 1) +
facet_grid(id~velH) +
geom_point(data = rbind(Data_GLM2,Data_GLM) %>% filter(id %in% c("Across All", "s01","s02", "s03", "s04", "s05", "s06", "s08")), aes(Difference,Yes/Total,color = Congruent), alpha = 0.2, size = 0.7) +
scale_color_manual(name = "",
values = c(Red,BlauUB,LightBlauUB),
labels = c("No Motion","Same Direction","Opposite Directions")) +
scale_x_continuous("Difference between Comparison and Test (m/s)") +
scale_y_continuous("Probability to choose Test",breaks = c(0.2,0.5,0.8)) +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey") +
theme(legend.position = "top") +
ggtitle("Full psychometric functions")
ggsave("Poster VOR/All Psychometric Functions.jpg", w = 7, h = 10)
ggplot(Predictions, aes(Difference,Response,color = Motion)) +
geom_line(size = 2) +
scale_color_manual(name = "",
values = c(Red,BlauUB,LightBlauUB),
labels = c("No Motion","Same\nDirection","Opposite\nDirection")) +
xlab("Difference between Comp. and Test (m/s)") +
ylab("Probability Test Faster") +
theme(legend.position = "") +
ggtitle("Incomplete Compensation, Precision Cost") +
geom_hline(yintercept = 0.5, linetype = 2, color = "grey") +
geom_vline(xintercept = 0, linetype = 2, color = "grey") +
annotate("text", x = 2.2, y = 0.6, label = "No Motion\n(steeper slope,\nnot shifted)", color = Red, size = 6) +
annotate("text", x = 1.3, y = 0.2, label = "Opposite Directions\n(shifted right)", color = LightBlauUB, size = 6) +
annotate("text", x = -1, y = 0.8, label = "Same Direction\n(shifted left)", color = BlauUB, size = 6)
Dataframe_pvalues = read.csv(header = T, file = paste0(Where_Am_I(),"/Data/pvalues_Julia.csv"))
Dataframe_pvalues = Dataframe_AICs %>%
mutate(Optimizer = case_when(
label == "JuliaAIC_NeldMeader_AGP0" ~ "Julia: Nelder-Mead, nAGQ 0",
label == "JuliaAIC_bobyqa_AGP0" ~ "Julia: bobyqa, nAGQ 0",
label == "NelderMead_nAGQ0" ~ "R: Nelder-Mead, nAGQ 0",
label == "NelderMead_nAGQ1" ~ "R: Nelder-Mead, nAGQ 1",
label == "Bobyqa_nAGQ0" ~ "R: bobyqa, nAGQ 0",
label == "Bobyqa_nAGQ1" ~ "R: bobyqa, nAGQ 1",
label == "nloptwrap_nAGQ0" ~ "R: nloptwrap, nAGQ 0",
label == "nloptwrap_nAGQ1" ~ "R: nloptwrap, nAGQ 1")
)%>%
group_by(n,reps) %>%
mutate(MedianAIC_n_reps = median(AIC),
Median_pvalue_Accuracy_n_reps = median(Pvalues_Accuracy),
Median_pvalue_Interaction_n_reps = median(Pvalues_Interaction)) %>%
group_by(n,reps,label) %>%
mutate(MedianDuration = median(Duration),
SE_Duration_n_reps_label = SE(Duration),
MedianAIC_Difference = median(AIC)-MedianAIC_n_reps,
Median_Pvalue_Accuracy_Difference = median(Pvalues_Accuracy) - Median_pvalue_Accuracy_n_reps,
Median_Pvalue_Interaction_Difference = median(Pvalues_Interaction) - Median_pvalue_Interaction_n_reps)
ggplot(Dataframe_pvalues,aes(Pvalues_Accuracy, color = Optimizer)) +
geom_density(size = 2) +
coord_cartesian(ylim = c(0,5))
facet_grid(n~reps) +
ggsave("Figures/Duration for each Optimizer.jpg", w = 10, h = 5)
ggplot(Dataframe_pvalues,aes(round(Pvalues_Interaction,2), color = Optimizer, fill = Optimizer)) +
geom_histogram(bins = 20) +
facet_grid(.~Optimizer)
Dataframe_pvalues$Bin_Accuracy = 0
Dataframe_pvalues$Bin_Interaction = 0
for (i in (1:length(Dataframe_pvalues$iteration))){
Bins = seq(0.025,0.975,0.05)
Dataframe_pvalues$Bin_Accuracy[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Accuracy[i]))]+0.025
Dataframe_pvalues$Bin_Interaction[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Interaction[i]))]+0.025
print(i)
}
Dataframe_pvalues = Dataframe_pvalues %>%
group_by(Bin_Accuracy,Optimizer) %>%
mutate(BinCountAccuracy = length(Bin_Accuracy))%>%
group_by(Bin_Interaction,Optimizer) %>%
mutate(BinCountInteraction = length(Bin_Interaction))
ggplot(Dataframe_pvalues %>% filter(Program == "R"),aes(Bin_Accuracy,Optimizer, fill = BinCountAccuracy)) +
geom_tile() +
xlab("")
ggplot(Dataframe_pvalues,aes(Bin_Interaction,Optimizer, fill = BinCountInteraction)) +
geom_tile() +
xlab("")
ggplot(Dataframe_pvalues,aes(Bin_Accuracy,Optimizer, fill = BinCountAccuracy)) +
geom_tile() +
xlab("")
########################################################################
###########################compare p values#############################
########################################################################
Dataframe_pvalues = read.csv(header = T, file = paste0(Where_Am_I(),"/Data/pvalues_Julia.csv"))
Dataframe_pvalues = Dataframe_AICs %>%
mutate(Optimizer = case_when(
label == "JuliaAIC_NeldMeader_AGP0" ~ "Julia: Nelder-Mead, nAGQ 0",
label == "JuliaAIC_bobyqa_AGP0" ~ "Julia: bobyqa, nAGQ 0",
label == "NelderMead_nAGQ0" ~ "R: Nelder-Mead, nAGQ 0",
label == "NelderMead_nAGQ1" ~ "R: Nelder-Mead, nAGQ 1",
label == "Bobyqa_nAGQ0" ~ "R: bobyqa, nAGQ 0",
label == "Bobyqa_nAGQ1" ~ "R: bobyqa, nAGQ 1",
label == "nloptwrap_nAGQ0" ~ "R: nloptwrap, nAGQ 0",
label == "nloptwrap_nAGQ1" ~ "R: nloptwrap, nAGQ 1")
)%>%
group_by(n,reps) %>%
mutate(MedianAIC_n_reps = median(AIC),
Median_pvalue_Accuracy_n_reps = median(Pvalues_Accuracy),
Median_pvalue_Interaction_n_reps = median(Pvalues_Interaction)) %>%
group_by(n,reps,label) %>%
mutate(MedianDuration = median(Duration),
SE_Duration_n_reps_label = SE(Duration),
MedianAIC_Difference = median(AIC)-MedianAIC_n_reps,
Median_Pvalue_Accuracy_Difference = median(Pvalues_Accuracy) - Median_pvalue_Accuracy_n_reps,
Median_Pvalue_Interaction_Difference = median(Pvalues_Interaction) - Median_pvalue_Interaction_n_reps)
ggplot(Dataframe_pvalues,aes(Pvalues_Accuracy, color = Optimizer)) +
geom_density(size = 2) +
coord_cartesian(ylim = c(0,5))
facet_grid(n~reps) +
ggsave("Figures/Duration for each Optimizer.jpg", w = 10, h = 5)
ggplot(Dataframe_pvalues,aes(round(Pvalues_Interaction,2), color = Optimizer, fill = Optimizer)) +
geom_histogram(bins = 20) +
facet_grid(.~Optimizer)
Dataframe_pvalues$Bin_Accuracy = 0
Dataframe_pvalues$Bin_Interaction = 0
for (i in (1:length(Dataframe_pvalues$iteration))){
Bins = seq(0.025,0.975,0.05)
Dataframe_pvalues$Bin_Accuracy[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Accuracy[i]))]+0.025
Dataframe_pvalues$Bin_Interaction[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Interaction[i]))]+0.025
print(i)
}
Dataframe_pvalues = Dataframe_pvalues %>%
group_by(Bin_Accuracy,Optimizer) %>%
mutate(BinCountAccuracy = length(Bin_Accuracy))%>%
group_by(Bin_Interaction,Optimizer) %>%
mutate(BinCountInteraction = length(Bin_Interaction))
ggplot(Dataframe_pvalues,aes(Bin_Accuracy,Optimizer, fill = BinCountAccuracy)) +
geom_tile() +
xlab("")
########################################################################
###########################compare p values#############################
########################################################################
Dataframe_pvalues = read.csv(header = T, file = paste0(Where_Am_I(),"/Data/Pvalues_Julia.csv"))
Dataframe_pvalues = Dataframe_AICs %>%
mutate(Optimizer = case_when(
label == "JuliaAIC_NeldMeader_AGP0" ~ "Julia: Nelder-Mead, nAGQ 0",
label == "JuliaAIC_bobyqa_AGP0" ~ "Julia: bobyqa, nAGQ 0",
label == "NelderMead_nAGQ0" ~ "R: Nelder-Mead, nAGQ 0",
label == "NelderMead_nAGQ1" ~ "R: Nelder-Mead, nAGQ 1",
label == "Bobyqa_nAGQ0" ~ "R: bobyqa, nAGQ 0",
label == "Bobyqa_nAGQ1" ~ "R: bobyqa, nAGQ 1",
label == "nloptwrap_nAGQ0" ~ "R: nloptwrap, nAGQ 0",
label == "nloptwrap_nAGQ1" ~ "R: nloptwrap, nAGQ 1")
)%>%
group_by(n,reps) %>%
mutate(MedianAIC_n_reps = median(AIC),
Median_pvalue_Accuracy_n_reps = median(Pvalues_Accuracy),
Median_pvalue_Interaction_n_reps = median(Pvalues_Interaction)) %>%
group_by(n,reps,label) %>%
mutate(MedianDuration = median(Duration),
SE_Duration_n_reps_label = SE(Duration),
MedianAIC_Difference = median(AIC)-MedianAIC_n_reps,
Median_Pvalue_Accuracy_Difference = median(Pvalues_Accuracy) - Median_pvalue_Accuracy_n_reps,
Median_Pvalue_Interaction_Difference = median(Pvalues_Interaction) - Median_pvalue_Interaction_n_reps)
ggplot(Dataframe_pvalues,aes(Pvalues_Accuracy, color = Optimizer)) +
geom_density(size = 2) +
coord_cartesian(ylim = c(0,5))
facet_grid(n~reps) +
ggsave("Figures/Duration for each Optimizer.jpg", w = 10, h = 5)
ggplot(Dataframe_pvalues,aes(Pvalues_Accuracy, color = Optimizer)) +
geom_density(size = 2) +
coord_cartesian(ylim = c(0,5)) +
facet_grid(n~reps)
ggplot(Dataframe_pvalues,aes(round(Pvalues_Interaction,2), color = Optimizer, fill = Optimizer)) +
geom_histogram(bins = 20) +
facet_grid(.~Optimizer)
Dataframe_pvalues$Bin_Accuracy = 0
Dataframe_pvalues$Bin_Interaction = 0
for (i in (1:length(Dataframe_pvalues$iteration))){
Bins = seq(0.025,0.975,0.05)
Dataframe_pvalues$Bin_Accuracy[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Accuracy[i]))]+0.025
Dataframe_pvalues$Bin_Interaction[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Interaction[i]))]+0.025
print(i)
}
Dataframe_pvalues = Dataframe_pvalues %>%
group_by(Bin_Accuracy,Optimizer) %>%
mutate(BinCountAccuracy = length(Bin_Accuracy))%>%
group_by(Bin_Interaction,Optimizer) %>%
mutate(BinCountInteraction = length(Bin_Interaction))
ggplot(Dataframe_pvalues,aes(Bin_Accuracy,Optimizer, fill = BinCountAccuracy)) +
geom_tile() +
xlab("")
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
require(quickpsy)
require(brms)
require(rstan)
#require(lmerTest)
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
source("Utilities/PowerFunctions.r")
#optimize for fitting of Bayesian Linear Mixed Models (packages "rstan", "bmrs")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=corei7')
########################################################################
###########################compare p values#############################
########################################################################
Dataframe_pvalues = read.csv(header = T, file = paste0(Where_Am_I(),"/Data/Pvalues_Julia.csv"))
Dataframe_pvalues = Dataframe_AICs %>%
mutate(Optimizer = case_when(
label == "JuliaAIC_NeldMeader_AGP0" ~ "Julia: Nelder-Mead, nAGQ 0",
label == "JuliaAIC_bobyqa_AGP0" ~ "Julia: bobyqa, nAGQ 0",
label == "NelderMead_nAGQ0" ~ "R: Nelder-Mead, nAGQ 0",
label == "NelderMead_nAGQ1" ~ "R: Nelder-Mead, nAGQ 1",
label == "Bobyqa_nAGQ0" ~ "R: bobyqa, nAGQ 0",
label == "Bobyqa_nAGQ1" ~ "R: bobyqa, nAGQ 1",
label == "nloptwrap_nAGQ0" ~ "R: nloptwrap, nAGQ 0",
label == "nloptwrap_nAGQ1" ~ "R: nloptwrap, nAGQ 1")
)%>%
group_by(n,reps) %>%
mutate(MedianAIC_n_reps = median(AIC),
Median_pvalue_Accuracy_n_reps = median(Pvalues_Accuracy),
Median_pvalue_Interaction_n_reps = median(Pvalues_Interaction)) %>%
group_by(n,reps,label) %>%
mutate(MedianDuration = median(Duration),
SE_Duration_n_reps_label = SE(Duration),
MedianAIC_Difference = median(AIC)-MedianAIC_n_reps,
Median_Pvalue_Accuracy_Difference = median(Pvalues_Accuracy) - Median_pvalue_Accuracy_n_reps,
Median_Pvalue_Interaction_Difference = median(Pvalues_Interaction) - Median_pvalue_Interaction_n_reps)
ggplot(Dataframe_pvalues,aes(Pvalues_Accuracy, color = Optimizer)) +
geom_density(size = 2) +
coord_cartesian(ylim = c(0,5)) +
facet_grid(n~reps)
ggsave("Figures/Duration for each Optimizer.jpg", w = 10, h = 5)
ggplot(Dataframe_pvalues,aes(round(Pvalues_Interaction,2), color = Optimizer, fill = Optimizer)) +
geom_histogram(bins = 20) +
facet_grid(.~Optimizer)
Dataframe_pvalues$Bin_Accuracy = 0
Dataframe_pvalues$Bin_Interaction = 0
for (i in (1:length(Dataframe_pvalues$iteration))){
Bins = seq(0.025,0.975,0.05)
Dataframe_pvalues$Bin_Accuracy[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Accuracy[i]))]+0.025
Dataframe_pvalues$Bin_Interaction[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Interaction[i]))]+0.025
print(i)
}
Dataframe_pvalues = Dataframe_pvalues %>%
group_by(Bin_Accuracy,Optimizer) %>%
mutate(BinCountAccuracy = length(Bin_Accuracy))%>%
group_by(Bin_Interaction,Optimizer) %>%
mutate(BinCountInteraction = length(Bin_Interaction))
ggplot(Dataframe_pvalues,aes(Bin_Accuracy,Optimizer, fill = BinCountAccuracy)) +
geom_tile() +
xlab("")
Dataframe_pvalues
Where_Am_I()
paste0(Where_Am_I(),"/Data/Pvalues_Julia.csv")
read.csv(header = T, file = paste0(Where_Am_I(),"/Data/Pvalues_Julia.csv"))
########################################################################
###########################compare p values#############################
########################################################################
Dataframe_pvalues = read.csv(header = T, file = paste0(Where_Am_I(),"/Data/Pvalues_Julia.csv"))
Dataframe_pvalues
Dataframe_pvalues = Dataframe_pvalues %>%
mutate(Optimizer = case_when(
label == "JuliaAIC_NeldMeader_AGP0" ~ "Julia: Nelder-Mead, nAGQ 0",
label == "JuliaAIC_bobyqa_AGP0" ~ "Julia: bobyqa, nAGQ 0",
label == "NelderMead_nAGQ0" ~ "R: Nelder-Mead, nAGQ 0",
label == "NelderMead_nAGQ1" ~ "R: Nelder-Mead, nAGQ 1",
label == "Bobyqa_nAGQ0" ~ "R: bobyqa, nAGQ 0",
label == "Bobyqa_nAGQ1" ~ "R: bobyqa, nAGQ 1",
label == "nloptwrap_nAGQ0" ~ "R: nloptwrap, nAGQ 0",
label == "nloptwrap_nAGQ1" ~ "R: nloptwrap, nAGQ 1")
)%>%
group_by(n,reps) %>%
mutate(MedianAIC_n_reps = median(AIC),
Median_pvalue_Accuracy_n_reps = median(Pvalues_Accuracy),
Median_pvalue_Interaction_n_reps = median(Pvalues_Interaction)) %>%
group_by(n,reps,label) %>%
mutate(MedianDuration = median(Duration),
SE_Duration_n_reps_label = SE(Duration),
MedianAIC_Difference = median(AIC)-MedianAIC_n_reps,
Median_Pvalue_Accuracy_Difference = median(Pvalues_Accuracy) - Median_pvalue_Accuracy_n_reps,
Median_Pvalue_Interaction_Difference = median(Pvalues_Interaction) - Median_pvalue_Interaction_n_reps)
ggplot(Dataframe_pvalues,aes(Pvalues_Accuracy, color = Optimizer)) +
geom_density(size = 2) +
coord_cartesian(ylim = c(0,5)) +
facet_grid(n~reps)
ggsave("Figures/Duration for each Optimizer.jpg", w = 10, h = 5)
ggplot(Dataframe_pvalues,aes(round(Pvalues_Interaction,2), color = Optimizer, fill = Optimizer)) +
geom_histogram(bins = 20) +
facet_grid(.~Optimizer)
Dataframe_pvalues$Bin_Accuracy = 0
Dataframe_pvalues$Bin_Interaction = 0
for (i in (1:length(Dataframe_pvalues$iteration))){
Bins = seq(0.025,0.975,0.05)
Dataframe_pvalues$Bin_Accuracy[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Accuracy[i]))]+0.025
Dataframe_pvalues$Bin_Interaction[i] = Bins[which.min(abs(Bins-Dataframe_pvalues$Pvalues_Interaction[i]))]+0.025
print(i)
}
Dataframe_pvalues = Dataframe_pvalues %>%
group_by(Bin_Accuracy,Optimizer) %>%
mutate(BinCountAccuracy = length(Bin_Accuracy))%>%
group_by(Bin_Interaction,Optimizer) %>%
mutate(BinCountInteraction = length(Bin_Interaction))
ggplot(Dataframe_pvalues,aes(Bin_Accuracy,Optimizer, fill = BinCountAccuracy)) +
geom_tile() +
xlab("")
ggplot(Dataframe_pvalues,aes(Bin_Accuracy,Optimizer, fill = BinCountAccuracy)) +
geom_tile() +
xlab("")
ggplot(Dataframe_pvalues,aes(Bin_Interaction,Optimizer, fill = BinCountInteraction)) +
geom_tile() +
xlab("")
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
require(quickpsy)
require(brms)
require(rstan)
#require(lmerTest)
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
source("Utilities/PowerFunctions.r")
#optimize for fitting of Bayesian Linear Mixed Models (packages "rstan", "bmrs")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=corei7')
#set.seed(9121)
ID = paste0("s",1:15)
ConditionOfInterest = c(0,1)
StandardValues = c(5,8)
reps = 1:100
PSE_Difference = -0.1
JND_Difference = 0.25
Multiplicator_PSE_Standard = 0
Multiplicator_SD_Standard = 0.15
Type_ResponseFunction = "Normal"
SD_ResponseFunction = 0.1
Mean_Variability_Between = 0.1
SD_Variability_Between = 0.1
pnorm(10.73,10,10*0.108)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, StandardValues=StandardValues, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,Mean_Variability_Between), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,SD_Variability_Between)) #how much variability is in the standard deviations of the psychometric functions between subjects?
Psychometric = Psychometric %>%
mutate(
Mean_Standard = StandardValues+StandardValues*Multiplicator_PSE_Standard,
SD_Standard = StandardValues*Multiplicator_SD_Standard,
Mean = (Mean_Standard + (ConditionOfInterest==1)*Mean_Standard*PSE_Difference),
SD = abs(SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference))
Psychometric = Psychometric %>%
mutate(
Mean = Mean*PSE_Factor_ID,
SD = SD*SD_Factor_ID)
if (Type_ResponseFunction == "normal"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = pnorm(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
} else if (Type_ResponseFunction == "Cauchy"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
#} else if (Type_ResponseFunction == "uniform"){
#
#  Psychometric = Psychometric %>%
#  mutate(
#      staircase_factor = seq(SD_ResponseFunction[1],SD_ResponseFunction[2],(SD_ResponseFunction[2]-SD_ResponseFunc#tion[1]/6)))
} else{
print("distribution not valid")
}
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues)
Psychometric = Psychometric %>%
mutate(
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(staircase_factor-1) < 0.75) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
GLMM = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest*Difference + (ConditionOfInterest+Difference| ID) + (ConditionOfInterest+Difference| StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
GLMM2 = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest*Difference + (Difference| ID) + (Difference| StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
summary(GLMM2)
summary(GLMM)
hallo = anova(GLMM,GLMM2)
hallo
Psychometric %>%
group_by(ConditionOfInterest, StandardValues) %>%
slice(1)
PsychometricFunctions = quickpsy(Psychometric,Difference,Answer,grouping = .(ConditionOfInterest,ID,StandardValues), bootstrap = "none")
plot(PsychometricFunctions) +
scale_color_manual(name = "",
values = c(Red,BlauUB),
labels = c("Control","Experimental")) +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey")
ggsave("Figure02.jpg", w = 10, h = 5)
ResponseDistributions = data.frame(
Value=c(rcauchy(1650,1,0.05),
rnorm(1650,1,0.1),
rep(c(0.7,0.85,1,1.15,1.3),1650/5)),
label = c(rep("Cauchy",1650),
rep("Normal",1650),
rep("Uniform",1650))
) %>% filter(abs(Value-1) < 0.5)
ggplot(ResponseDistributions %>% filter(label %in% c("Cauchy","Normal")), aes(Value,color = label)) +
geom_density(size=2) +
#  coord_cartesian(xlim=c(0.5,1.5)) +
xlab("Stimulus Intensity") +
ylab("Density") +
scale_color_manual(name = "Distribution\nType",
values = c(Red,BlauUB),
labels = c("Cauchy","Gaussian"))
ggsave("Figure1 Distributions.jpg", w = 6, h = 4)
########################################################################
###########################compare p values#############################
########################################################################
Dataframe_pvalues = read.csv(header = T, file = paste0(Where_Am_I(),"/Data/Pvalues_Julia.csv"))
Dataframe_pvalues$label
