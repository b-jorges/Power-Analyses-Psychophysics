Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues)
Psychometric = Psychometric %>%
mutate(
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "Condition",
values = c(Red,BlauUB))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(StandardValues~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "Condition",
values = c(Red,BlauUB))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(StandardValues~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "Condition",
values = c(Red,BlauUB))
mod1 = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | SecondaryCondition),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod1 = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
anova(mod1,mod2)$`Pr(>Chisq)`[2]
summary(mod1)
anova(mod1,mod2)$`Pr(>Chisq)`[2]
summary(mod1)
mod1 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | SecondaryCondition),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod1 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest) + Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
anova(mod1,mod2)$`Pr(>Chisq)`[2] ##Model 1 beats model 2
summary(mod1)
SimulatePsychometricFunction_Staircase = function(ID, ConditionOfInterest, SecondaryCondition, reps, PSE_Difference, JND_Difference, Mean_Standard, SD_Standard, SD_ResponseFuntion){
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, SecondaryCondition=SecondaryCondition, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,0.1),
SD_Factor_ID = rnorm(1,1,0.1))
Psychometric = Psychometric %>%
mutate(
Mean = (SecondaryCondition + (ConditionOfInterest==1)*SecondaryCondition*PSE_Difference)*PSE_Factor_ID,
SD = abs((SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference)*SD_Factor_ID),
staircase_factor = rcauchy(length(reps),1,SD_ResponseFuntion),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - SecondaryCondition,
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,SecondaryCondition,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
Psychometric
}
Analyze_Pychometric_Accuracy = function(Psychometric){
TimeBeginning = Sys.time()
mod1 = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | SecondaryCondition),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ (Difference  | ID) + (Difference  | SecondaryCondition),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
print(TimeBeginning - Sys.time())
p = anova(mod1,mod2)$`Pr(>Chisq)`[2] ##Model 1 beats model 2
print(p)
p
}
Analyze_Pychometric_Precision = function(Psychometric){
TimeBeginning = Sys.time()
mod1 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | SecondaryCondition),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest) + Difference + (Difference  | ID) + (Difference  | SecondaryCondition),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
p = anova(mod1,mod2)$`Pr(>Chisq)`[2] ##Model 1 beats model 2
print(TimeBeginning - Sys.time())
print(p)
p
}
NumbersOfSubjects = c(10,12,14,16,18,20) #for how many subjects are we simulating the power?
PowerPerN_Precision = c()
for (i in NumbersOfSubjects){
ID = paste0("s",1:i)
Power_Precision = c()
nIterations = 500 #how many data frames should we simulate per number of subjects? more data frames makes for a more reliable estimate of the power
out <- replicate(nIterations, { #this function performs the number of iterations indicated above and stores the result for each in "out"
Analyze_Pychometric_Precision(SimulatePsychometricFunction_Staircase(ID, ConditionOfInterest, SecondaryCondition, reps, PSE_Difference, JND_Difference, Mean_Standard, SD_Standard, SD_ResponseFuntion))})
hist(out) ###Distribution of p values
Power_Precision = mean(out < 0.05) ###Power is the times the difference between the two models is significant
PowerPerN_Precision = c(PowerPerN_Precision,Power_Precision) ###This is a vector with the power for each n for the JNDs
paste0("For ", i, " subjects: ", Power_Precision) #gives an estimate of the power for each n
}
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
set.seed(912)
ID = paste0("s",1:5)
ConditionOfInterest = c(0,1)
StandardValues = c(6.6, 8, 10)
reps = seq(1,55,1)
PSE_Difference = 1/8
JND_Difference = 1/3
PSE_Standard = StandardValues
Multiplicator_SD_Standard = 0.108
SD_Standard = StandardValues*Multiplicator_SD_Standard
Type_ResponseFunction = "Cauchy"
SD_ResponseFunction = 0.06
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, StandardValues=StandardValues, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,0.1), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,0.1)) #how much variability is in the standard deviations of the psychometric functions between subjects?
Psychometric = Psychometric %>%
mutate(
Mean = (StandardValues + (ConditionOfInterest==1)*StandardValues*PSE_Difference),
SD = abs(SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference))
Psychometric = Psychometric %>%
mutate(
Mean = Mean*PSE_Factor_ID,
SD = SD*SD_Factor_ID)
if (Type_ResponseFunction == "normal"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = pnorm(length(reps),1,SD_ResponseFunction))
} else if (Type_ResponseFunction == "Cauchy"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction))
#} else if (Type_ResponseFunction == "uniform"){
#
#  Psychometric = Psychometric %>%
#  mutate(
#      staircase_factor = seq(SD_ResponseFunction[1],SD_ResponseFunction[2],(SD_ResponseFunction[2]-SD_ResponseFunc#tion[1]/6)))
} else{
print("distribution not valid")
}
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues)
Psychometric = Psychometric %>%
mutate(
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(StandardValues~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "Condition",
values = c(Red,BlauUB))
require(lmerTest)
summary(mod1)$coefficients
mod1 = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(mod1)$coefficients
mod1 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest):Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
summary(mod1)$coefficients
mod1 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
summary(mod1)$coefficients
?quickpsy
?quickpsy
install.packages("quickpsy")
?quickpsy
install.packages("quickpsy")
?quickpsy
install.packages("quickpsy")
?quickpsy()
install.packages("quickpsy")
?quickpsy()
?quickpsy()
install.packages("quickpsy")
require(quickpsy)
To simulate the power with a given set of parameters, we need to execute the above procedure sufficient times (we recommend 500 times, although this might be too time consuming for studies with a high count of subjects and or trials; further below we give some recommendations on how to speed up the relatively slow glmer() model fitting implementation in the R package lme4), and calculate the ratio of simulations in which the test model is significantly better than the test model, given a certain false positive rate (typically 0.05). To this end, we establish functions containing the above procedure:
require(quickpsy)
?quickpsy
require(quickpsy)
quickpsy(Psychometric,Difference,ConditionOfInterest,StandardValues)
quickpsy(Psychometric,Difference,ConditionOfInterest)
quickpsy(Psychometric,Difference,Response)
quickpsy(Psychometric,Difference,Response,grouping = .(ID,ConditionOfInterest,StandardValues))
Data = quickpsy(Psychometric,Difference,Response,grouping = .(ID,ConditionOfInterest,StandardValues))
Parameters = quickpsy(Psychometric,Difference,Response,grouping = .(ID,ConditionOfInterest,StandardValues))
Parameters = quickpsy(Psychometric,Difference,Answer,grouping = .(ID,ConditionOfInterest,StandardValues))
Parameters
Parameters2 = quickpsy(Psychometric,Difference,Answer,grouping = .(ID,ConditionOfInterest,StandardValues), bootstrap = "none")
Parameters2
Parameters
Parameters2
Parameters
Parameters2
Parameters$aic
Parameters2$aic
Parameters2 = quickpsy(Psychometric,Difference,Answer,grouping = .(ID,ConditionOfInterest,StandardValues), bootstrap = "none")
Parameters2$aic
Parameters
Parameters2
Parameters
View(Parameters)
Parameters = quickpsy(Psychometric,Difference,Answer,grouping = .(ID,ConditionOfInterest,StandardValues), bootstrap = "none")
Parameters
Parameters2 = Parameters %>%
filter(parn == "p1")
Parameters$par
Parameters = quickpsy(Psychometric,Difference,Answer,grouping = .(ID,ConditionOfInterest,StandardValues), bootstrap = "none")$par
Parameters2 = Parameters %>%
filter(parn == "p1")
Parameters2
Parameters2 = Parameters %>%
filter(parn == "p1")
Parameters2
Parameters2 = Parameters %>%
filter(parn == "p0")
Parameters2
Parameters2 = Parameters %>%
filter(parn == "p2")
Parameters2
Parameters2 = Parameters %>%
filter(parn == "p1")
Parameters2
Parameters2$SD = Parameters$parn[Parameters$par == "p2"]
Parameters$parn
Parameters2$SD = Parameters$par[Parameters$parn == "p2"]
Parameters2
Parameters2 = Parameters %>%
filter(parn == "p1") %>%
select(ID,ConditionOfInterest,Mean=par)
Parameters2 = Parameters %>%
filter(parn == "p1") %>%
select(ID,ConditionOfInterest,Mean=par, StandardValues)
Parameters2$SD = Parameters$par[Parameters$parn == "p2"]
Parameters2
?aov()
aov(Mean ~ ID*as.factor(ConditionOfInterst)*StandardValues)
aov(Mean ~ ID*as.factor(ConditionOfInterst)*StandardValues,Parameters2)
aov(Mean ~ ID*as.factor(ConditionOfInterest)*StandardValues,Parameters2)
ANOVA_Mean = aov(Mean ~ ID*as.factor(ConditionOfInterest)*StandardValues,Parameters2)
ANOVA_Mean = aov(Mean ~ ID*as.factor(ConditionOfInterest)*StandardValues,Parameters2)
ANOVA_Mean$coefficients
ANOVA_Mean$effects
ANOVA_Mean = aov(Mean ~ as.factor(ConditionOfInterest)*StandardValues,Parameters2)
ANOVA_Mean
T.test_Mean = t.test(Parameters2$Mean[Parameters2$ConditionOfInterest == 1],Parameters2$Mean[Parameters2$ConditionOfInterest == 0])
T.test_Mean
ANOVA_Mean
ANOVA_Mean = aov(Mean ~ as.factor(ConditionOfInterest)*StandardValues,Parameters2)
ANOVA_Mean$residuals
ANOVA_Mean$fitted.values
ANOVA_Mean$assign
ANOVA_Mean$contrasts
ANOVA_Mean$model
ANOVA_Mean$terms
summary(ANOVA_Mean)
summary(ANOVA_Mean)
ANOVA_SD = aov(SD ~ as.factor(ConditionOfInterest)*StandardValues,Parameters2)
summary(ANOVA_SD)
SimulatePsychometricFunction_Staircase = function(ID, ConditionOfInterest, StandardValues, reps, PSE_Difference, JND_Difference, Mean_Standard, SD_Standard, SD_ResponseFunction,Mean_Variability_Between = 0.1, SD_Variability = 0.1){
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, StandardValues=StandardValues, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,Mean_Variability_Between),
SD_Factor_ID = rnorm(1,1,SD_Variability))
Psychometric = Psychometric %>%
mutate(
Mean = (StandardValues + (ConditionOfInterest==1)*StandardValues*PSE_Difference)*PSE_Factor_ID,
SD = abs((SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference)*SD_Factor_ID),
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues,
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
Psychometric
}
Analyze_Pychometric_Accuracy = function(Psychometric){
TimeBeginning = Sys.time()
mod1 = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
print(TimeBeginning - Sys.time()) ###This is two show how long each iteration takes
p = anova(mod1,mod2)$`Pr(>Chisq)`[2] ##Model 1 beats model 2
print(p)
p
}
Analyze_Pychometric_Precision = function(Psychometric){
TimeBeginning = Sys.time()
mod1 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest) + Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
print(TimeBeginning - Sys.time())  ###This is two show how long each iteration takes
p = anova(mod1,mod2)$`Pr(>Chisq)`[2] ##Model 1 beats model 2
print(p)
p
}
#NumbersOfSubjects = c(10,12,14,16,18,20) #for how many subjects are we simulating the power?
NumbersOfSubjects = c(2)
Dataframe = SimulatePsychometricFunction_Staircase(ID, ConditionOfInterest, StandardValues, reps, PSE_Difference, JND_Difference, Mean_Standard, SD_Standard, SD_ResponseFunction)
Analyze_Pychometric_Precision_GLMM(Dataframe)
Analyze_Pychometric_Accuracy_GLMM = function(Psychometric){
TimeBeginning = Sys.time()
mod1 = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
print(TimeBeginning - Sys.time()) ###This is two show how long each iteration takes
p = anova(mod1,mod2)$`Pr(>Chisq)`[2] ##Model 1 beats model 2
print(p)
p
}
Analyze_Pychometric_Precision_GLMM = function(Psychometric){
TimeBeginning = Sys.time()
mod1 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
mod2 = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest) + Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
print(TimeBeginning - Sys.time())  ###This is two show how long each iteration takes
p = anova(mod1,mod2)$`Pr(>Chisq)`[2] ##Model 1 beats model 2
print(p)
p
}
Analyze_Pychometric_Precision_GLMM(Dataframe)
Analyze_Pychometric_Accuracy_GLMM(Dataframe)
p = summary(GLMM_Accuracy)$coefficients
GLMM_Accuracy = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
p = summary(GLMM_Accuracy)$coefficients
GLMM_Accuracy
summary(GLMM_Accuracy)$coefficients
p = summary(GLMM_Accuracy)$coefficients[7]
p
p = summary(GLMM_Accuracy)$coefficients[8]
Analyze_Pychometric_Accuracy_GLMM = function(Psychometric){
TimeBeginning = Sys.time()
GLMM_Accuracy = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
p = summary(GLMM_Accuracy)$coefficients[8]
print(TimeBeginning - Sys.time()) ###This is two show how long each iteration takes
print(p)
p
}
GLMM_Precision = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
p = summary(GLMM_Precision)$coefficients[]
p
p = summary(GLMM_Precision)$coefficients[16]
p
Analyze_Pychometric_Precision_GLMM = function(Psychometric){
TimeBeginning = Sys.time()
GLMM_Precision = glmer(cbind(Yes, Total - Yes) ~ as.factor(ConditionOfInterest)*Difference + (Difference  | ID) + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
p = summary(GLMM_Precision)$coefficients[16]
print(TimeBeginning - Sys.time())  ###This is two show how long each iteration takes
print(p)
p
}
Analyze_Pychometric_Accuracy_GLMM = function(Psychometric){
TimeBeginning = Sys.time()
GLMM_Accuracy = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
p = summary(GLMM_Accuracy)$coefficients[8]
print(TimeBeginning - Sys.time()) ###This is two show how long each iteration takes
print(p)
p
}
Parameters = quickpsy(Psychometric,Difference,Answer,grouping = .(ID,ConditionOfInterest,StandardValues), bootstrap = "none")$par
Parameters2 = Parameters %>%
filter(parn == "p1") %>%
select(ID,ConditionOfInterest,Mean=par, StandardValues)
Parameters2$SD = Parameters$par[Parameters$parn == "p2"]
Parameters2
TimeBeginning = Sys.time()
ANOVA_Mean = aov(Mean ~ as.factor(ConditionOfInterest)*StandardValues,Parameters2)
summary(ANOVA_Mean)
Coefficients = summary(ANOVA_Mean)
Coefficients
Coefficients[12]
Coefficients[2]
Coefficients[1,]
Coefficients
