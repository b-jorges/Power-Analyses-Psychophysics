SD = abs((SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference)*SD_Factor_ID),
#Now we draw stimulus strengths. For the typical staircase, they are not uniformly distributed, but rather concentrated around the PSE
#A normal distribution with a low standard deviation might be appropriate, or a normal function with an extremely high kurtosis,
#another option is the Cauchy function;
staircase_factor = rcauchy(length(reps),1,SD_ResponseFuntion), #here we draw a multiplier for each trial
Presented_TestStimulusStrength = Mean*staircase_factor, ###translates from values around 1 to values around PSE
####Get difference between Standard stimulus strength and Test stimulus strength
Difference = Presented_TestStimulusStrength - SecondaryCondition,
#We assume that the responses can be adequately captured by a Cummulative Gaussian Distribution ...
#with the Means and SDs we simulated above.
#This line gives us the response probability for each trial:
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,SecondaryCondition,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
```
```{r setup, include=FALSE}
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test")
```
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
theme(legend.title = FALSE)
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
theme(legend.title = "")
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala")
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
color = c(Red,LightRed))
---
title: "PowerAnalysesPsychophysics"
author: "Björn Jörges"
date: "1/31/2020"
output: html_document
---
```{r setup, include=FALSE}
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
set.seed(912)
```
```{r Staircase1, include=FALSE,echo=FALSE}
ID = paste0("s",1:10) #For how many subjects do you want to simulate the power?
ConditionOfInterest = c(0,1) #Values of a categorical variable of interest (e. g. high contrast and low contrast)
SecondaryCondition = c(6.6, 8, 10) #intensities of the comparison stimuli
reps = seq(1,55,1) #how many trials do we expect for each condition?
PSE_Difference = 1/8 #by how much does the PSE differ between test and comparison conditions, in units of the comparison PSE
JND_Difference = 1/3 #by how much does the JND differ between test and comparison conditions, in units of the comparison JND
PSE_Standard = SecondaryCondition #Mean of the cummulative Gaussian in the standard condition
SD_Standard = SecondaryCondition*0.1 #SD of the cummulative Gaussian in the standard condition, see "XXXXX.r" on how to get standard deviations from Weber Fractions
SD_ResponseFuntion = 0.06 #Standard deviation of the distribution we draw the presented stimulus strengths from (normal distribution), or its scale (Cauchy distribution)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, SecondaryCondition=SecondaryCondition, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,0.1), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,0.1)) #how much variability is in the standard deviations of the psychometric functions between subjects?
#Next, we are going to simulating PSEs and JNDs for each condition
Psychometric = Psychometric %>%
mutate(
#PSE is calculated as the strength of the comparison stimulus; in the test condition, we add the
Mean = (SecondaryCondition + (ConditionOfInterest==1)*SecondaryCondition*PSE_Difference)*PSE_Factor_ID,
SD = abs((SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference)*SD_Factor_ID),
#Now we draw stimulus strengths. For the typical staircase, they are not uniformly distributed, but rather concentrated around the PSE
#A normal distribution with a low standard deviation might be appropriate, or a normal function with an extremely high kurtosis,
#another option is the Cauchy function;
staircase_factor = rcauchy(length(reps),1,SD_ResponseFuntion), #here we draw a multiplier for each trial
Presented_TestStimulusStrength = Mean*staircase_factor, ###translates from values around 1 to values around PSE
####Get difference between Standard stimulus strength and Test stimulus strength
Difference = Presented_TestStimulusStrength - SecondaryCondition,
#We assume that the responses can be adequately captured by a Cummulative Gaussian Distribution ...
#with the Means and SDs we simulated above.
#This line gives us the response probability for each trial:
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,SecondaryCondition,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
```
```{r setup, include=FALSE}
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
color = c(Red,LightRed))
```
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,LightRed))
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
set.seed(912)
---
title: "PowerAnalysesPsychophysics"
author: "Björn Jörges"
date: "1/31/2020"
output: html_document
---
```{r setup, include=FALSE}
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
set.seed(912)
```
```{r Staircase1, include=FALSE,echo=FALSE}
ID = paste0("s",1:10) #For how many subjects do you want to simulate the power?
ConditionOfInterest = c(0,1) #Values of a categorical variable of interest (e. g. high contrast and low contrast)
SecondaryCondition = c(6.6, 8, 10) #intensities of the comparison stimuli
reps = seq(1,55,1) #how many trials do we expect for each condition?
PSE_Difference = 1/8 #by how much does the PSE differ between test and comparison conditions, in units of the comparison PSE
JND_Difference = 1/3 #by how much does the JND differ between test and comparison conditions, in units of the comparison JND
PSE_Standard = SecondaryCondition #Mean of the cummulative Gaussian in the standard condition
SD_Standard = SecondaryCondition*0.1 #SD of the cummulative Gaussian in the standard condition, see "XXXXX.r" on how to get standard deviations from Weber Fractions
SD_ResponseFuntion = 0.06 #Standard deviation of the distribution we draw the presented stimulus strengths from (normal distribution), or its scale (Cauchy distribution)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, SecondaryCondition=SecondaryCondition, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,0.1), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,0.1)) #how much variability is in the standard deviations of the psychometric functions between subjects?
#Next, we are going to simulating PSEs and JNDs for each condition
Psychometric = Psychometric %>%
mutate(
#PSE is calculated as the strength of the comparison stimulus; in the test condition, we add the
Mean = (SecondaryCondition + (ConditionOfInterest==1)*SecondaryCondition*PSE_Difference)*PSE_Factor_ID,
SD = abs((SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference)*SD_Factor_ID),
#Now we draw stimulus strengths. For the typical staircase, they are not uniformly distributed, but rather concentrated around the PSE
#A normal distribution with a low standard deviation might be appropriate, or a normal function with an extremely high kurtosis,
#another option is the Cauchy function;
staircase_factor = rcauchy(length(reps),1,SD_ResponseFuntion), #here we draw a multiplier for each trial
Presented_TestStimulusStrength = Mean*staircase_factor, ###translates from values around 1 to values around PSE
####Get difference between Standard stimulus strength and Test stimulus strength
Difference = Presented_TestStimulusStrength - SecondaryCondition,
#We assume that the responses can be adequately captured by a Cummulative Gaussian Distribution ...
#with the Means and SDs we simulated above.
#This line gives us the response probability for each trial:
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,SecondaryCondition,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
```
```{r setup, include=FALSE}
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red))
```
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,LightRed))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test")
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,LightRed))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,Yellow))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,Turquoise))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,BlauUB))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,BlauUB)) +
xlim(c(-2,0,2))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,BlauUB)) +
scale_x_continuous(breaks = c(-2,0,2))
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,BlauUB)) +
scale_x_continuous(breaks = c(-3,0,3))
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
set.seed(912)
ID = paste0("s",1:5) #For how many subjects do you want to simulate the power?
---
title: "PowerAnalysesPsychophysics"
author: "Björn Jörges"
date: "1/31/2020"
output: html_document
---
```{r setup, include=FALSE}
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
set.seed(912)
```
```{r Staircase1, include=FALSE,echo=FALSE}
ID = paste0("s",1:5) #For how many subjects do you want to simulate the power?
ConditionOfInterest = c(0,1) #Values of a categorical variable of interest (e. g. high contrast and low contrast)
SecondaryCondition = c(6.6, 8, 10) #intensities of the comparison stimuli
reps = seq(1,55,1) #how many trials do we expect for each condition?
PSE_Difference = 1/8 #by how much does the PSE differ between test and comparison conditions, in units of the comparison PSE
JND_Difference = 1/3 #by how much does the JND differ between test and comparison conditions, in units of the comparison JND
PSE_Standard = SecondaryCondition #Mean of the cummulative Gaussian in the standard condition
SD_Standard = SecondaryCondition*0.1 #SD of the cummulative Gaussian in the standard condition, see "XXXXX.r" on how to get standard deviations from Weber Fractions
SD_ResponseFuntion = 0.06 #Standard deviation of the distribution we draw the presented stimulus strengths from (normal distribution), or its scale (Cauchy distribution)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, SecondaryCondition=SecondaryCondition, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,0.1), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,0.1)) #how much variability is in the standard deviations of the psychometric functions between subjects?
#Next, we are going to simulating PSEs and JNDs for each condition
Psychometric = Psychometric %>%
mutate(
#PSE is calculated as the strength of the comparison stimulus; in the test condition, we add the
Mean = (SecondaryCondition + (ConditionOfInterest==1)*SecondaryCondition*PSE_Difference)*PSE_Factor_ID,
SD = abs((SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference)*SD_Factor_ID),
#Now we draw stimulus strengths. For the typical staircase, they are not uniformly distributed, but rather concentrated around the PSE
#A normal distribution with a low standard deviation might be appropriate, or a normal function with an extremely high kurtosis,
#another option is the Cauchy function;
staircase_factor = rcauchy(length(reps),1,SD_ResponseFuntion), #here we draw a multiplier for each trial
Presented_TestStimulusStrength = Mean*staircase_factor, ###translates from values around 1 to values around PSE
####Get difference between Standard stimulus strength and Test stimulus strength
Difference = Presented_TestStimulusStrength - SecondaryCondition,
#We assume that the responses can be adequately captured by a Cummulative Gaussian Distribution ...
#with the Means and SDs we simulated above.
#This line gives us the response probability for each trial:
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(Difference) < 0.5*abs(Mean)) %>%
group_by(ID,ConditionOfInterest,SecondaryCondition,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
```
```{r setup, include=FALSE}
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,BlauUB)) +
scale_x_continuous(breaks = c(-3,0,3))
```
```{r setup, include=FALSE}
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,BlauUB)) +
scale_x_continuous(breaks = c(-3,0,3))
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
set.seed(912)
ggplot(Psychometric, aes(Difference, Answer, color = as.factor(ConditionOfInterest))) +
binomial_smooth() +
facet_grid(SecondaryCondition~ID) +
geom_vline(xintercept = 0, color = "grey") +
geom_hline(yintercept = 0.5, color = "grey") +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
scale_color_manual(name = "lala",
values = c(Red,BlauUB))
