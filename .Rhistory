SD_ResponseFunction = 0.1
Mean_Variability_Between = 0.1
SD_Variability_Between = 0.1
pnorm(10.73,10,10*0.108)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, StandardValues=StandardValues, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,Mean_Variability_Between), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,SD_Variability_Between)) #how much variability is in the standard deviations of the psychometric functions between subjects?
Psychometric = Psychometric %>%
mutate(
Mean_Standard = StandardValues+StandardValues*Multiplicator_PSE_Standard,
SD_Standard = StandardValues*Multiplicator_SD_Standard,
Mean = (Mean_Standard + (ConditionOfInterest==1)*Mean_Standard*PSE_Difference),
SD = abs(SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference))
Psychometric = Psychometric %>%
mutate(
Mean = Mean*PSE_Factor_ID,
SD = SD*SD_Factor_ID)
ResponseDistributions = data.frame(
Value=c(rcauchy(1650,1,0.05),
rnorm(1650,1,0.1),
rep(c(0.7,0.85,1,1.15,1.3),1650/5)),
label = c(rep("Cauchy",1650),
rep("Normal",1650),
rep("Uniform",1650))
) %>% filter(abs(Value-1) < 0.5)
ggplot(ResponseDistributions %>% filter(label %in% c("Cauchy","Normal")), aes(Value,color = label)) +
geom_density(size=2) +
#  coord_cartesian(xlim=c(0.5,1.5)) +
xlab("Stimulus Intensity") +
ylab("Density") +
scale_color_manual(name = "Distribution\nType",
values = c(Red,BlauUB),
labels = c("Cauchy","Gaussian"))
ggsave("Figure1 Distributions.jpg", w = 6, h = 4)
if (Type_ResponseFunction == "normal"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = pnorm(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
} else if (Type_ResponseFunction == "Cauchy"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
#} else if (Type_ResponseFunction == "uniform"){
#
#  Psychometric = Psychometric %>%
#  mutate(
#      staircase_factor = seq(SD_ResponseFunction[1],SD_ResponseFunction[2],(SD_ResponseFunction[2]-SD_ResponseFunc#tion[1]/6)))
} else{
print("distribution not valid")
}
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues)
Psychometric = Psychometric %>%
mutate(
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(staircase_factor-1) < 0.75) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
PsychometricFunctions = quickpsy(Psychometric,Difference,Answer,grouping = .(ConditionOfInterest,ID,StandardValues), bootstrap = "none")
plot(PsychometricFunctions) +
scale_color_manual(name = "",
values = c(Red,BlauUB),
labels = c("Control","Experimental")) +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey")
ggsave("Figure02.jpg", w = 10, h = 5)
GLMM_Accuracy = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Accuracy)$coefficients
GLMM_Precision = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest*Difference + (Difference| ID) + (Difference| StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Precision)$coefficients
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
require(quickpsy)
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
source("Utilities/PowerFunctions.r")
set.seed(9121)
ID = paste0("s",1:5)
ConditionOfInterest = c(0,1)
StandardValues = c(8,10)
reps = 1:55
PSE_Difference = 0.2
JND_Difference = 0.3
Multiplicator_PSE_Standard = 0
Multiplicator_SD_Standard = 0.15
Type_ResponseFunction = "Normal"
SD_ResponseFunction = 0.1
Mean_Variability_Between = 0.1
SD_Variability_Between = 0.1
pnorm(10.73,10,10*0.108)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, StandardValues=StandardValues, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,Mean_Variability_Between), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,SD_Variability_Between)) #how much variability is in the standard deviations of the psychometric functions between subjects?
Psychometric = Psychometric %>%
mutate(
Mean_Standard = StandardValues+StandardValues*Multiplicator_PSE_Standard,
SD_Standard = StandardValues*Multiplicator_SD_Standard,
Mean = (Mean_Standard + (ConditionOfInterest==1)*Mean_Standard*PSE_Difference),
SD = abs(SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference))
Psychometric = Psychometric %>%
mutate(
Mean = Mean*PSE_Factor_ID,
SD = SD*SD_Factor_ID)
ResponseDistributions = data.frame(
Value=c(rcauchy(1650,1,0.05),
rnorm(1650,1,0.1),
rep(c(0.7,0.85,1,1.15,1.3),1650/5)),
label = c(rep("Cauchy",1650),
rep("Normal",1650),
rep("Uniform",1650))
) %>% filter(abs(Value-1) < 0.5)
ggplot(ResponseDistributions %>% filter(label %in% c("Cauchy","Normal")), aes(Value,color = label)) +
geom_density(size=2) +
#  coord_cartesian(xlim=c(0.5,1.5)) +
xlab("Stimulus Intensity") +
ylab("Density") +
scale_color_manual(name = "Distribution\nType",
values = c(Red,BlauUB),
labels = c("Cauchy","Gaussian"))
ggsave("Figure1 Distributions.jpg", w = 6, h = 4)
if (Type_ResponseFunction == "normal"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = pnorm(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
} else if (Type_ResponseFunction == "Cauchy"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
#} else if (Type_ResponseFunction == "uniform"){
#
#  Psychometric = Psychometric %>%
#  mutate(
#      staircase_factor = seq(SD_ResponseFunction[1],SD_ResponseFunction[2],(SD_ResponseFunction[2]-SD_ResponseFunc#tion[1]/6)))
} else{
print("distribution not valid")
}
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues)
Psychometric = Psychometric %>%
mutate(
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(staircase_factor-1) < 0.75) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
PsychometricFunctions = quickpsy(Psychometric,Difference,Answer,grouping = .(ConditionOfInterest,ID,StandardValues), bootstrap = "none")
plot(PsychometricFunctions) +
scale_color_manual(name = "",
values = c(Red,BlauUB),
labels = c("Control","Experimental")) +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey")
ggsave("Figure02.jpg", w = 10, h = 5)
GLMM_Accuracy = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Accuracy)$coefficients
GLMM_Precision = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest*Difference + (Difference| ID) + (Difference| StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Precision)$coefficients
Psychometric$StandardValues
BayesianAnalysis = brm(bf(Yes ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues),
sigma ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues)),
data = Psychometric, family = bernoulli())
BayesianAnalysis = brm(bf(Yes ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues),
sigma ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues)),
data = Psychometric,
family = bernoulli(),
nl=TRUE)
BayesianAnalysis = brm(bf(Yes ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues),
data = Psychometric,
family = bernoulli(),
nl=TRUE))
BayesianAnalysis = brm(bf(Yes ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues)),
data = Psychometric,
family = bernoulli(),
nl=TRUE)
BayesianAnalysis = brm(bf(Yes ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues)),
data = Psychometric,
family = bernoulli())
BayesianAnalysis
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
require(quickpsy)
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
source("Utilities/PowerFunctions.r")
set.seed(9121)
ID = paste0("s",1:15)
ConditionOfInterest = c(0,1)
StandardValues = c(8,10)
reps = 1:100
PSE_Difference = 0.2
JND_Difference = 0.3
Multiplicator_PSE_Standard = 0
Multiplicator_SD_Standard = 0.15
Type_ResponseFunction = "Normal"
SD_ResponseFunction = 0.1
Mean_Variability_Between = 0.1
SD_Variability_Between = 0.1
pnorm(10.73,10,10*0.108)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, StandardValues=StandardValues, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,Mean_Variability_Between), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,SD_Variability_Between)) #how much variability is in the standard deviations of the psychometric functions between subjects?
Psychometric = Psychometric %>%
mutate(
Mean_Standard = StandardValues+StandardValues*Multiplicator_PSE_Standard,
SD_Standard = StandardValues*Multiplicator_SD_Standard,
Mean = (Mean_Standard + (ConditionOfInterest==1)*Mean_Standard*PSE_Difference),
SD = abs(SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference))
Psychometric = Psychometric %>%
mutate(
Mean = Mean*PSE_Factor_ID,
SD = SD*SD_Factor_ID)
ResponseDistributions = data.frame(
Value=c(rcauchy(1650,1,0.05),
rnorm(1650,1,0.1),
rep(c(0.7,0.85,1,1.15,1.3),1650/5)),
label = c(rep("Cauchy",1650),
rep("Normal",1650),
rep("Uniform",1650))
) %>% filter(abs(Value-1) < 0.5)
ggplot(ResponseDistributions %>% filter(label %in% c("Cauchy","Normal")), aes(Value,color = label)) +
geom_density(size=2) +
#  coord_cartesian(xlim=c(0.5,1.5)) +
xlab("Stimulus Intensity") +
ylab("Density") +
scale_color_manual(name = "Distribution\nType",
values = c(Red,BlauUB),
labels = c("Cauchy","Gaussian"))
ggsave("Figure1 Distributions.jpg", w = 6, h = 4)
if (Type_ResponseFunction == "normal"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = pnorm(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
} else if (Type_ResponseFunction == "Cauchy"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
#} else if (Type_ResponseFunction == "uniform"){
#
#  Psychometric = Psychometric %>%
#  mutate(
#      staircase_factor = seq(SD_ResponseFunction[1],SD_ResponseFunction[2],(SD_ResponseFunction[2]-SD_ResponseFunc#tion[1]/6)))
} else{
print("distribution not valid")
}
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues)
Psychometric = Psychometric %>%
mutate(
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(staircase_factor-1) < 0.75) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
PsychometricFunctions = quickpsy(Psychometric,Difference,Answer,grouping = .(ConditionOfInterest,ID,StandardValues), bootstrap = "none")
plot(PsychometricFunctions) +
scale_color_manual(name = "",
values = c(Red,BlauUB),
labels = c("Control","Experimental")) +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey")
ggsave("Figure02.jpg", w = 10, h = 5)
GLMM_Accuracy = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Accuracy)$coefficients
GLMM_Precision = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest*Difference + (Difference| ID) + (Difference| StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Precision)$coefficients
BayesianAnalysis = brm(bf(Yes ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues)),
data = Psychometric,
family = bernoulli())
BayesianAnalysis
plot(BayesianAnalysis)
###Pull the whole repository
require(dplyr)
require(tidyverse)
require(lme4)
require(ggplot2)
require(cowplot)
theme_set(theme_cowplot())
require(quickpsy)
Where_Am_I <- function(path=T){
if (path == T){
dirname(rstudioapi::getSourceEditorContext()$path)
}
else {
rstudioapi::getSourceEditorContext()$path
}
}
binomial_smooth <- function(...) {
geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)}
setwd(Where_Am_I())
source("Utilities/parabolic.r")
source("Utilities/functions.r")
source("Utilities/colourschemes.r")
source("Utilities/PowerFunctions.r")
set.seed(9121)
ID = paste0("s",1:15)
ConditionOfInterest = c(0,1)
StandardValues = c(8,10)
reps = 1:100
PSE_Difference = 0
JND_Difference = 0.3
Multiplicator_PSE_Standard = 0
Multiplicator_SD_Standard = 0.15
Type_ResponseFunction = "Normal"
SD_ResponseFunction = 0.1
Mean_Variability_Between = 0.1
SD_Variability_Between = 0.1
pnorm(10.73,10,10*0.108)
Psychometric = expand.grid(ID=ID, ConditionOfInterest=ConditionOfInterest, StandardValues=StandardValues, reps = reps)
Psychometric = Psychometric %>%
group_by(ID) %>%#
mutate(PSE_Factor_ID = rnorm(1,1,Mean_Variability_Between), #how much variability is in the means of the psychometric functions between subjects?
SD_Factor_ID = rnorm(1,1,SD_Variability_Between)) #how much variability is in the standard deviations of the psychometric functions between subjects?
Psychometric = Psychometric %>%
mutate(
Mean_Standard = StandardValues+StandardValues*Multiplicator_PSE_Standard,
SD_Standard = StandardValues*Multiplicator_SD_Standard,
Mean = (Mean_Standard + (ConditionOfInterest==1)*Mean_Standard*PSE_Difference),
SD = abs(SD_Standard + (ConditionOfInterest==1)*SD_Standard*JND_Difference))
Psychometric = Psychometric %>%
mutate(
Mean = Mean*PSE_Factor_ID,
SD = SD*SD_Factor_ID)
ResponseDistributions = data.frame(
Value=c(rcauchy(1650,1,0.05),
rnorm(1650,1,0.1),
rep(c(0.7,0.85,1,1.15,1.3),1650/5)),
label = c(rep("Cauchy",1650),
rep("Normal",1650),
rep("Uniform",1650))
) %>% filter(abs(Value-1) < 0.5)
ggplot(ResponseDistributions %>% filter(label %in% c("Cauchy","Normal")), aes(Value,color = label)) +
geom_density(size=2) +
#  coord_cartesian(xlim=c(0.5,1.5)) +
xlab("Stimulus Intensity") +
ylab("Density") +
scale_color_manual(name = "Distribution\nType",
values = c(Red,BlauUB),
labels = c("Cauchy","Gaussian"))
ggsave("Figure1 Distributions.jpg", w = 6, h = 4)
if (Type_ResponseFunction == "normal"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = pnorm(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
} else if (Type_ResponseFunction == "Cauchy"){
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction*(1+ConditionOfInterest*JND_Difference)))
#} else if (Type_ResponseFunction == "uniform"){
#
#  Psychometric = Psychometric %>%
#  mutate(
#      staircase_factor = seq(SD_ResponseFunction[1],SD_ResponseFunction[2],(SD_ResponseFunction[2]-SD_ResponseFunc#tion[1]/6)))
} else{
print("distribution not valid")
}
Psychometric = Psychometric %>%
mutate(
staircase_factor = rcauchy(length(reps),1,SD_ResponseFunction),
Presented_TestStimulusStrength = Mean*staircase_factor,
Difference = Presented_TestStimulusStrength - StandardValues)
Psychometric = Psychometric %>%
mutate(
AnswerProbability = pnorm(Presented_TestStimulusStrength,Mean,SD),
##get binary answers ("Test was stronger" yes/no) from probabilities for each trial
Answer = as.numeric(rbernoulli(length(AnswerProbability),AnswerProbability))
)
###prepare for glmer() - needs sum of YES/Total per stimulus strength and condition
Psychometric = Psychometric %>%
filter(abs(staircase_factor-1) < 0.75) %>%
group_by(ID,ConditionOfInterest,StandardValues,Difference) %>%
mutate(Yes = sum(Answer==1),
Total = length(ConditionOfInterest))
PsychometricFunctions = quickpsy(Psychometric,Difference,Answer,grouping = .(ConditionOfInterest,ID,StandardValues), bootstrap = "none")
plot(PsychometricFunctions) +
scale_color_manual(name = "",
values = c(Red,BlauUB),
labels = c("Control","Experimental")) +
xlab("Difference between Comparison and Test") +
ylab("Probability to choose Test") +
geom_vline(linetype = 2, xintercept = 0, color = "grey") +
geom_hline(linetype = 2, yintercept = 0.5, color = "grey")
ggsave("Figure02.jpg", w = 10, h = 5)
GLMM_Accuracy = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest + (Difference  | ID)  + (Difference  | StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Accuracy)$coefficients
GLMM_Precision = glmer(cbind(Yes, Total - Yes) ~ ConditionOfInterest*Difference + (Difference| ID) + (Difference| StandardValues),
family = binomial(link = "probit"),
data = Psychometric,
nAGQ = 0,
control = glmerControl(optimizer = "nloptwrap"))
require(lmerTest)
summary(GLMM_Precision)$coefficients
BayesianAnalysis = brm(bf(Yes ~ ConditionOfInterest*Difference + (Difference | ID) + (Difference | StandardValues)),
data = Psychometric,
family = bernoulli())
BayesianAnalysis2 = brm(bf(Yes ~ ConditionOfInterest*Difference + (1 | ID) + (1 | StandardValues)),
data = Psychometric,
family = bernoulli())
BayesianAnalysis
BayesianAnalysis2
BayesianAnalysis
BayesianAnalysis
BayesianAnalysis2
BayesianAnalysis
BayesianAnalysis2
BayesianAnalysis
BayesianAnalysis2
